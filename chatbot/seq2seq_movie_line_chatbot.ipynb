{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a conversational chatbot using a Sequence-to-sequence framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in data and do some cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'    \\nif j == 1:\\n    movie_line = '\\t' + movie_line.lower() + '\\n'\\n    for char in movie_line:\\n        if char not in target_characters:\\n            target_characters.add(char)\\nelse:\\n    for char in movie_line:\\n        if char not in input_characters:\\n            input_characters.add(char)\\nline_dict[j].append(movie_line)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 800  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 900000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = '../Downloads/cornell/movie_lines.txt'\n",
    "with open(data_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "line_dict = {}\n",
    "line_dict[0] = []\n",
    "line_dict[1] = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "movie_lines, line_numbers, scene_ids, movies = [], [], [], []\n",
    "for i, line in enumerate(lines):\n",
    "    # print(line)\n",
    "    j = i % 2\n",
    "    splitted = line.split('+++$+++')\n",
    "    # print((splitted))\n",
    "    # input('stopped')\n",
    "    if len(splitted) == 5:\n",
    "        movie_lines.append(splitted[-1].strip().lower())\n",
    "        line_numbers.append(splitted[0].strip())\n",
    "        scene_ids.append(splitted[1].strip())\n",
    "        movies.append(splitted[2].strip())\n",
    "\n",
    "script_df = pd.DataFrame({'movie_line': movie_lines, \n",
    "                          'line_number': line_numbers,\n",
    "                          'scene_id': scene_ids,\n",
    "                          'movie_id': movies})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213472\n"
     ]
    }
   ],
   "source": [
    "script_df['line_number'] = script_df['line_number'].map(lambda x: int(x.replace('L', '')))\n",
    "script_df = script_df.sort_values(by = ['movie_id', 'line_number' ])\n",
    "script_df = script_df[script_df['movie_line'].map(lambda x: len(x) < 60)]\n",
    "script_df.head(60)\n",
    "print(len(script_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n"
     ]
    }
   ],
   "source": [
    "input_comments, output_comments = [], []\n",
    "for i in range(1, len(script_df)):\n",
    "    row = script_df.iloc[i]\n",
    "    row0 = script_df.iloc[i-1]\n",
    "    if ((row['movie_id'] == row0['movie_id']) &\n",
    "        # (row['scene_id'] == row0['scene_id']) &\n",
    "        (row['line_number'] == (row0['line_number']+1))):\n",
    "            input_comments.append(row0['movie_line'])\n",
    "            output_comments.append(row['movie_line'])\n",
    "    if i % 1000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we have a simple DF with inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_comment</th>\n",
       "      <th>output_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>did you change your hair?</td>\n",
       "      <td>no.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no.</td>\n",
       "      <td>you might wanna think about it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it was a bratwurst.  i was eating lunch.</td>\n",
       "      <td>with the teeth of your zipper?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with the teeth of your zipper?</td>\n",
       "      <td>you the new guy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you the new guy?</td>\n",
       "      <td>so they tell me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              input_comment                  output_comment\n",
       "0                 did you change your hair?                             no.\n",
       "1                                       no.  you might wanna think about it\n",
       "2  it was a bratwurst.  i was eating lunch.  with the teeth of your zipper?\n",
       "3            with the teeth of your zipper?                you the new guy?\n",
       "4                          you the new guy?              so they tell me..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'input_comment': input_comments, 'output_comment': output_comments})# [0:200000]\n",
    "df.to_csv('movie_line_training.csv')\n",
    "print(len(df))\n",
    "df.head()\n",
    "# df[df['input_comment'] == 'They do to!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remoe any that contain our termination characters\n",
    "df = df[~df['input_comment'].str.contains('~')]\n",
    "df = df[~df['input_comment'].str.contains('`')]\n",
    "df = df[~df['output_comment'].str.contains('~')]\n",
    "df = df[~df['output_comment'].str.contains('`')]\n",
    "df = df[df['input_comment'] != '[removed]']\n",
    "df = df[df['input_comment'] != '[deleted]']\n",
    "df = df[df['output_comment'] != '[removed]']\n",
    "df = df[df['output_comment'] != '[deleted]']\n",
    "df[['input_comment', 'output_comment']].to_csv('movie_line_training.csv')\n",
    "input_texts = list(df['input_comment'])\n",
    "target_texts = list(df['output_comment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize at the character level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_characters = set()\n",
    "new_targets = []\n",
    "target_characters = set()\n",
    "for i in input_texts:\n",
    "    for char in i:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "for j in target_texts:\n",
    "    target_text = '~' + j + '`'\n",
    "    new_targets.append(target_text)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "target_texts = new_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 129458\n",
      "Number of unique input tokens: 64\n",
      "Number of unique output tokens: 64\n",
      "Max sequence length for inputs: 59\n",
      "Max sequence length for outputs: 61\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122985 samples, validate on 6473 samples\n",
      "Epoch 1/200\n",
      "122985/122985 [==============================] - 600s 5ms/step - loss: 0.8856 - val_loss: 0.7184\n",
      "Epoch 2/200\n",
      "122985/122985 [==============================] - 583s 5ms/step - loss: 0.6872 - val_loss: 0.6437\n",
      "Epoch 3/200\n",
      "122985/122985 [==============================] - 677s 6ms/step - loss: 0.6374 - val_loss: 0.6118\n",
      "Epoch 4/200\n",
      "122985/122985 [==============================] - 635s 5ms/step - loss: 0.6121 - val_loss: 0.5962\n",
      "Epoch 5/200\n",
      "122985/122985 [==============================] - 626s 5ms/step - loss: 0.5972 - val_loss: 0.5868\n",
      "Epoch 6/200\n",
      "122985/122985 [==============================] - 649s 5ms/step - loss: 0.5854 - val_loss: 0.5778\n",
      "Epoch 7/200\n",
      "122985/122985 [==============================] - 663s 5ms/step - loss: 0.5760 - val_loss: 0.5724\n",
      "Epoch 8/200\n",
      "122985/122985 [==============================] - 665s 5ms/step - loss: 0.5686 - val_loss: 0.5679\n",
      "Epoch 9/200\n",
      "122985/122985 [==============================] - 638s 5ms/step - loss: 0.5625 - val_loss: 0.5654\n",
      "Epoch 10/200\n",
      "122985/122985 [==============================] - 611s 5ms/step - loss: 0.5575 - val_loss: 0.5612\n",
      "Epoch 11/200\n",
      "122985/122985 [==============================] - 605s 5ms/step - loss: 0.5532 - val_loss: 0.5595\n",
      "Epoch 12/200\n",
      "122985/122985 [==============================] - 603s 5ms/step - loss: 0.5494 - val_loss: 0.5583\n",
      "Epoch 13/200\n",
      "122985/122985 [==============================] - 597s 5ms/step - loss: 0.5460 - val_loss: 0.5571\n",
      "Epoch 14/200\n",
      "122985/122985 [==============================] - 585s 5ms/step - loss: 0.5430 - val_loss: 0.5558\n",
      "Epoch 15/200\n",
      "122985/122985 [==============================] - 589s 5ms/step - loss: 0.5403 - val_loss: 0.5542\n",
      "Epoch 16/200\n",
      "122985/122985 [==============================] - 585s 5ms/step - loss: 0.5378 - val_loss: 0.5540\n",
      "Epoch 17/200\n",
      "122985/122985 [==============================] - 576s 5ms/step - loss: 0.5355 - val_loss: 0.5541\n",
      "Epoch 18/200\n",
      "122985/122985 [==============================] - 577s 5ms/step - loss: 0.5335 - val_loss: 0.5535\n",
      "Epoch 19/200\n",
      "122985/122985 [==============================] - 577s 5ms/step - loss: 0.5316 - val_loss: 0.5525\n",
      "Epoch 20/200\n",
      "122985/122985 [==============================] - 571s 5ms/step - loss: 0.5298 - val_loss: 0.5528\n",
      "Epoch 21/200\n",
      "122985/122985 [==============================] - 579s 5ms/step - loss: 0.5281 - val_loss: 0.5523\n",
      "Epoch 22/200\n",
      "122985/122985 [==============================] - 573s 5ms/step - loss: 0.5266 - val_loss: 0.5524\n",
      "Epoch 23/200\n",
      "122985/122985 [==============================] - 573s 5ms/step - loss: 0.5251 - val_loss: 0.5527\n",
      "Epoch 24/200\n",
      "122985/122985 [==============================] - 573s 5ms/step - loss: 0.5237 - val_loss: 0.5523\n",
      "Epoch 25/200\n",
      "122985/122985 [==============================] - 581s 5ms/step - loss: 0.5224 - val_loss: 0.5513\n",
      "Epoch 26/200\n",
      "122985/122985 [==============================] - 577s 5ms/step - loss: 0.5211 - val_loss: 0.5528\n",
      "Epoch 27/200\n",
      "122985/122985 [==============================] - 576s 5ms/step - loss: 0.5199 - val_loss: 0.5524\n",
      "Epoch 28/200\n",
      "122985/122985 [==============================] - 577s 5ms/step - loss: 0.5188 - val_loss: 0.5537\n",
      "Epoch 29/200\n",
      "122985/122985 [==============================] - 571s 5ms/step - loss: 0.5177 - val_loss: 0.5532\n",
      "Epoch 30/200\n",
      "122985/122985 [==============================] - 570s 5ms/step - loss: 0.5167 - val_loss: 0.5536\n",
      "Epoch 31/200\n",
      "122985/122985 [==============================] - 569s 5ms/step - loss: 0.5156 - val_loss: 0.5539\n",
      "Epoch 32/200\n",
      "122985/122985 [==============================] - 567s 5ms/step - loss: 0.5146 - val_loss: 0.5544\n",
      "Epoch 33/200\n",
      "122985/122985 [==============================] - 542s 4ms/step - loss: 0.5137 - val_loss: 0.5541\n",
      "Epoch 34/200\n",
      "122985/122985 [==============================] - 509s 4ms/step - loss: 0.5128 - val_loss: 0.5565\n",
      "Epoch 35/200\n",
      "122985/122985 [==============================] - 503s 4ms/step - loss: 0.5119 - val_loss: 0.5555\n",
      "Epoch 36/200\n",
      "122985/122985 [==============================] - 501s 4ms/step - loss: 0.5110 - val_loss: 0.5548\n",
      "Epoch 37/200\n",
      "122985/122985 [==============================] - 501s 4ms/step - loss: 0.5101 - val_loss: 0.5556\n",
      "Epoch 38/200\n",
      "122985/122985 [==============================] - 532s 4ms/step - loss: 0.5094 - val_loss: 0.5557\n",
      "Epoch 39/200\n",
      "122985/122985 [==============================] - 557s 5ms/step - loss: 0.5085 - val_loss: 0.5575\n",
      "Epoch 40/200\n",
      "122985/122985 [==============================] - 573s 5ms/step - loss: 0.5078 - val_loss: 0.5563\n",
      "Epoch 41/200\n",
      "122985/122985 [==============================] - 545s 4ms/step - loss: 0.5070 - val_loss: 0.5574\n",
      "Epoch 42/200\n",
      "122985/122985 [==============================] - 566s 5ms/step - loss: 0.5062 - val_loss: 0.5569\n",
      "Epoch 43/200\n",
      "122985/122985 [==============================] - 544s 4ms/step - loss: 0.5055 - val_loss: 0.5570\n",
      "Epoch 44/200\n",
      "122985/122985 [==============================] - 545s 4ms/step - loss: 0.5048 - val_loss: 0.5575\n",
      "Epoch 45/200\n",
      "122985/122985 [==============================] - 552s 4ms/step - loss: 0.5041 - val_loss: 0.5579\n",
      "Epoch 46/200\n",
      "122985/122985 [==============================] - 547s 4ms/step - loss: 0.5034 - val_loss: 0.5589\n",
      "Epoch 47/200\n",
      "122985/122985 [==============================] - 557s 5ms/step - loss: 0.5028 - val_loss: 0.5589\n",
      "Epoch 48/200\n",
      "122985/122985 [==============================] - 534s 4ms/step - loss: 0.5022 - val_loss: 0.5602\n",
      "Epoch 49/200\n",
      "122985/122985 [==============================] - 525s 4ms/step - loss: 0.5015 - val_loss: 0.5591\n",
      "Epoch 50/200\n",
      "122985/122985 [==============================] - 548s 4ms/step - loss: 0.5010 - val_loss: 0.5606\n",
      "Epoch 51/200\n",
      "122985/122985 [==============================] - 537s 4ms/step - loss: 0.5003 - val_loss: 0.5600\n",
      "Epoch 52/200\n",
      "122985/122985 [==============================] - 546s 4ms/step - loss: 0.4997 - val_loss: 0.5606\n",
      "Epoch 53/200\n",
      "122985/122985 [==============================] - 547s 4ms/step - loss: 0.4992 - val_loss: 0.5619\n",
      "Epoch 54/200\n",
      "122985/122985 [==============================] - 555s 5ms/step - loss: 0.4987 - val_loss: 0.5607\n",
      "Epoch 55/200\n",
      "122985/122985 [==============================] - 547s 4ms/step - loss: 0.4981 - val_loss: 0.5620\n",
      "Epoch 56/200\n",
      "122985/122985 [==============================] - 536s 4ms/step - loss: 0.4976 - val_loss: 0.5624\n",
      "Epoch 57/200\n",
      "122985/122985 [==============================] - 568s 5ms/step - loss: 0.4971 - val_loss: 0.5632\n",
      "Epoch 58/200\n",
      "122985/122985 [==============================] - 4474s 36ms/step - loss: 0.4967 - val_loss: 0.5632\n",
      "Epoch 59/200\n",
      "122985/122985 [==============================] - 508s 4ms/step - loss: 0.4961 - val_loss: 0.5627\n",
      "Epoch 60/200\n",
      "122985/122985 [==============================] - 497s 4ms/step - loss: 0.4956 - val_loss: 0.5637\n",
      "Epoch 61/200\n",
      "122985/122985 [==============================] - 496s 4ms/step - loss: 0.4951 - val_loss: 0.5642\n",
      "Epoch 62/200\n",
      "122985/122985 [==============================] - 546s 4ms/step - loss: 0.4948 - val_loss: 0.5637\n",
      "Epoch 63/200\n",
      "122985/122985 [==============================] - 578s 5ms/step - loss: 0.4943 - val_loss: 0.5642\n",
      "Epoch 64/200\n",
      "122985/122985 [==============================] - 620s 5ms/step - loss: 0.4939 - val_loss: 0.5640\n",
      "Epoch 65/200\n",
      "122985/122985 [==============================] - 643s 5ms/step - loss: 0.4935 - val_loss: 0.5655\n",
      "Epoch 66/200\n",
      "122985/122985 [==============================] - 623s 5ms/step - loss: 0.4932 - val_loss: 0.5652\n",
      "Epoch 67/200\n",
      "122985/122985 [==============================] - 615s 5ms/step - loss: 0.4927 - val_loss: 0.5659\n",
      "Epoch 68/200\n",
      "122985/122985 [==============================] - 608s 5ms/step - loss: 0.4924 - val_loss: 0.5671\n",
      "Epoch 69/200\n",
      "122985/122985 [==============================] - 615s 5ms/step - loss: 0.4920 - val_loss: 0.5675\n",
      "Epoch 70/200\n",
      "122985/122985 [==============================] - 706s 6ms/step - loss: 0.4916 - val_loss: 0.5668\n",
      "Epoch 71/200\n",
      "122985/122985 [==============================] - 699s 6ms/step - loss: 0.4912 - val_loss: 0.5677\n",
      "Epoch 72/200\n",
      "122985/122985 [==============================] - 690s 6ms/step - loss: 0.4909 - val_loss: 0.5676\n",
      "Epoch 73/200\n",
      "122985/122985 [==============================] - 667s 5ms/step - loss: 0.4906 - val_loss: 0.5691\n",
      "Epoch 74/200\n",
      "122985/122985 [==============================] - 629s 5ms/step - loss: 0.4903 - val_loss: 0.5664\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122985/122985 [==============================] - 722s 6ms/step - loss: 0.4899 - val_loss: 0.5683\n",
      "Epoch 76/200\n",
      "122985/122985 [==============================] - 647s 5ms/step - loss: 0.4895 - val_loss: 0.5682\n",
      "Epoch 77/200\n",
      "122985/122985 [==============================] - 629s 5ms/step - loss: 0.4893 - val_loss: 0.5686\n",
      "Epoch 78/200\n",
      "122985/122985 [==============================] - 603s 5ms/step - loss: 0.4889 - val_loss: 0.5685\n",
      "Epoch 79/200\n",
      "122985/122985 [==============================] - 605s 5ms/step - loss: 0.4886 - val_loss: 0.5693\n",
      "Epoch 80/200\n",
      "122985/122985 [==============================] - 631s 5ms/step - loss: 0.4884 - val_loss: 0.5703\n",
      "Epoch 81/200\n",
      "122985/122985 [==============================] - 638s 5ms/step - loss: 0.4881 - val_loss: 0.5698\n",
      "Epoch 82/200\n",
      "122985/122985 [==============================] - 612s 5ms/step - loss: 0.4879 - val_loss: 0.5698\n",
      "Epoch 83/200\n",
      "122985/122985 [==============================] - 606s 5ms/step - loss: 0.4875 - val_loss: 0.5712\n",
      "Epoch 84/200\n",
      "122985/122985 [==============================] - 606s 5ms/step - loss: 0.4873 - val_loss: 0.5698\n",
      "Epoch 85/200\n",
      "122985/122985 [==============================] - 600s 5ms/step - loss: 0.4871 - val_loss: 0.5720\n",
      "Epoch 86/200\n",
      "122985/122985 [==============================] - 560s 5ms/step - loss: 0.4868 - val_loss: 0.5713\n",
      "Epoch 87/200\n",
      "122985/122985 [==============================] - 574s 5ms/step - loss: 0.4865 - val_loss: 0.5708\n",
      "Epoch 88/200\n",
      "122985/122985 [==============================] - 576s 5ms/step - loss: 0.4863 - val_loss: 0.5723\n",
      "Epoch 89/200\n",
      "122985/122985 [==============================] - 597s 5ms/step - loss: 0.4861 - val_loss: 0.5697\n",
      "Epoch 90/200\n",
      "122985/122985 [==============================] - 584s 5ms/step - loss: 0.4858 - val_loss: 0.5731\n",
      "Epoch 91/200\n",
      "122985/122985 [==============================] - 590s 5ms/step - loss: 0.4856 - val_loss: 0.5721\n",
      "Epoch 92/200\n",
      "122985/122985 [==============================] - 609s 5ms/step - loss: 0.4853 - val_loss: 0.5720\n",
      "Epoch 93/200\n",
      "122985/122985 [==============================] - 7116s 58ms/step - loss: 0.4851 - val_loss: 0.5727\n",
      "Epoch 94/200\n",
      "122985/122985 [==============================] - 589s 5ms/step - loss: 0.4850 - val_loss: 0.5726\n",
      "Epoch 95/200\n",
      "122985/122985 [==============================] - 579s 5ms/step - loss: 0.4847 - val_loss: 0.5721\n",
      "Epoch 96/200\n",
      "122985/122985 [==============================] - 592s 5ms/step - loss: 0.4844 - val_loss: 0.5723\n",
      "Epoch 97/200\n",
      "122985/122985 [==============================] - 594s 5ms/step - loss: 0.4842 - val_loss: 0.5733\n",
      "Epoch 98/200\n",
      "122985/122985 [==============================] - 602s 5ms/step - loss: 0.4841 - val_loss: 0.5738\n",
      "Epoch 99/200\n",
      "122985/122985 [==============================] - 600s 5ms/step - loss: 0.4838 - val_loss: 0.5746\n",
      "Epoch 100/200\n",
      "122985/122985 [==============================] - 595s 5ms/step - loss: 0.4836 - val_loss: 0.5757\n",
      "Epoch 101/200\n",
      "122985/122985 [==============================] - 575s 5ms/step - loss: 0.4833 - val_loss: 0.5737\n",
      "Epoch 102/200\n",
      "122985/122985 [==============================] - 587s 5ms/step - loss: 0.4833 - val_loss: 0.5749\n",
      "Epoch 103/200\n",
      "122985/122985 [==============================] - 564s 5ms/step - loss: 0.4831 - val_loss: 0.5743\n",
      "Epoch 104/200\n",
      "122985/122985 [==============================] - 522s 4ms/step - loss: 0.4829 - val_loss: 0.5752\n",
      "Epoch 105/200\n",
      "122985/122985 [==============================] - 508s 4ms/step - loss: 0.4828 - val_loss: 0.5747\n",
      "Epoch 106/200\n",
      "122985/122985 [==============================] - 563s 5ms/step - loss: 0.4826 - val_loss: 0.5743\n",
      "Epoch 107/200\n",
      "122985/122985 [==============================] - 545s 4ms/step - loss: 0.4825 - val_loss: 0.5751\n",
      "Epoch 108/200\n",
      "122985/122985 [==============================] - 579s 5ms/step - loss: 0.4823 - val_loss: 0.5759\n",
      "Epoch 109/200\n",
      "122985/122985 [==============================] - 558s 5ms/step - loss: 0.4821 - val_loss: 0.5747\n",
      "Epoch 110/200\n",
      "122985/122985 [==============================] - 556s 5ms/step - loss: 0.4820 - val_loss: 0.5750\n",
      "Epoch 111/200\n",
      "122985/122985 [==============================] - 557s 5ms/step - loss: 0.4817 - val_loss: 0.5761\n",
      "Epoch 112/200\n",
      "122985/122985 [==============================] - 572s 5ms/step - loss: 0.4817 - val_loss: 0.5756\n",
      "Epoch 113/200\n",
      "122985/122985 [==============================] - 575s 5ms/step - loss: 0.4816 - val_loss: 0.5762\n",
      "Epoch 114/200\n",
      "122985/122985 [==============================] - 576s 5ms/step - loss: 0.4813 - val_loss: 0.5756\n",
      "Epoch 115/200\n",
      "122985/122985 [==============================] - 561s 5ms/step - loss: 0.4811 - val_loss: 0.5756\n",
      "Epoch 116/200\n",
      "122985/122985 [==============================] - 554s 5ms/step - loss: 0.4810 - val_loss: 0.5768\n",
      "Epoch 117/200\n",
      "122985/122985 [==============================] - 557s 5ms/step - loss: 0.4808 - val_loss: 0.5761\n",
      "Epoch 118/200\n",
      "122985/122985 [==============================] - 563s 5ms/step - loss: 0.4808 - val_loss: 0.5760\n",
      "Epoch 119/200\n",
      "122985/122985 [==============================] - 542s 4ms/step - loss: 0.4806 - val_loss: 0.5764\n",
      "Epoch 120/200\n",
      "122985/122985 [==============================] - 551s 4ms/step - loss: 0.4803 - val_loss: 0.5755\n",
      "Epoch 121/200\n",
      "122985/122985 [==============================] - 544s 4ms/step - loss: 0.4803 - val_loss: 0.5762\n",
      "Epoch 122/200\n",
      "122985/122985 [==============================] - 537s 4ms/step - loss: 0.4799 - val_loss: 0.5768\n",
      "Epoch 123/200\n",
      " 92608/122985 [=====================>........] - ETA: 2:08 - loss: 0.4783"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "a = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.05)\n",
    "# Save model\n",
    "model.save('movie_line_chatbot.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save some important parameters and the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py:2379: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "out_dict = {'input_token_index': input_token_index,\n",
    "            'target_token_index': target_token_index,\n",
    "            'num_encoder_tokens': num_encoder_tokens,\n",
    "            'num_decoder_tokens': num_decoder_tokens,\n",
    "            'max_encoder_seq_length': max_encoder_seq_length,\n",
    "            'max_decoder_seq_length': max_decoder_seq_length,\n",
    "            # 'encoder_inputs': encoder_inputs, check\n",
    "            # 'encoder_states': encoder_states,\n",
    "            'latent_dim': latent_dim}\n",
    "model_name = 'movieline_chatbot_model_v1.1'\n",
    "model.save(f'{model_name}.h5')\n",
    "pickle.dump(out_dict, open(f'{model_name}_model_dict.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13d13ac18>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(a.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12df31048>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['~']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '`' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how it does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: did you change your hair?\n",
      "Decoded sentence: yes.`\n",
      "-\n",
      "Input sentence: no.\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: it was a bratwurst.  i was eating lunch.\n",
      "Decoded sentence: well, i don't know what to say.`\n",
      "-\n",
      "Input sentence: with the teeth of your zipper?\n",
      "Decoded sentence: yeah.`\n",
      "-\n",
      "Input sentence: you the new guy?\n",
      "Decoded sentence: i don't know.`\n",
      "-\n",
      "Input sentence: so they tell me...\n",
      "Decoded sentence: so what do you want?`\n",
      "-\n",
      "Input sentence: c'mon.  i'm supposed to give you the tour.\n",
      "Decoded sentence: what are you doing here?`\n",
      "-\n",
      "Input sentence: so -- which dakota you from?\n",
      "Decoded sentence: so you got a lot of control?`\n",
      "-\n",
      "Input sentence: north, actually.  how'd you   ?\n",
      "Decoded sentence: i was a lot of contestion.`\n",
      "-\n",
      "Input sentence: how many people were in your old school?\n",
      "Decoded sentence: for me.  i was afraid of the car.`\n",
      "-\n",
      "Input sentence: thirty-two.\n",
      "Decoded sentence: you don't know what to do.`\n",
      "-\n",
      "Input sentence: get out!\n",
      "Decoded sentence: i want to go with you.`\n",
      "-\n",
      "Input sentence: how many people go here?\n",
      "Decoded sentence: three hundred charming.`\n",
      "-\n",
      "Input sentence: that girl -- i --\n",
      "Decoded sentence: you want to go to the back here?`\n",
      "-\n",
      "Input sentence: you burn, you pine, you perish?\n",
      "Decoded sentence: yes.`\n",
      "-\n",
      "Input sentence: who's that?\n",
      "Decoded sentence: the last time he don't look at me.`\n",
      "-\n",
      "Input sentence: he always look so\n",
      "Decoded sentence: i think i should take this shit in the first time.`\n",
      "-\n",
      "Input sentence: just a little.\n",
      "Decoded sentence: i think you don't know what to do.`\n",
      "-\n",
      "Input sentence: what's this?\n",
      "Decoded sentence: the completely or something.`\n",
      "-\n",
      "Input sentence: you know french?\n",
      "Decoded sentence: what?`\n",
      "-\n",
      "Input sentence: sure do ... my mom's from canada\n",
      "Decoded sentence: yes.`\n",
      "-\n",
      "Input sentence: guess who just signed up for a tutor?\n",
      "Decoded sentence: you don't want to go to the comminarian?`\n",
      "-\n",
      "Input sentence: you mean i'd get a chance to talk to her?\n",
      "Decoded sentence: no.`\n",
      "-\n",
      "Input sentence: they're running the rest of me next month.\n",
      "Decoded sentence: the police was a little on the back here.`\n",
      "-\n",
      "Input sentence: yeah, just a minor encounter with the shrew.\n",
      "Decoded sentence: that's right.`\n",
      "-\n",
      "Input sentence: that's her?  bianca's sister?\n",
      "Decoded sentence: they're not my father.`\n",
      "-\n",
      "Input sentence: in the microwave.\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: where've you been?\n",
      "Decoded sentence: i don't know.`\n",
      "-\n",
      "Input sentence: what's a synonym for throbbing?\n",
      "Decoded sentence: the show warm down the station.`\n",
      "-\n",
      "Input sentence: sarah lawrence is on the other side of the country.\n",
      "Decoded sentence: is that right?`\n",
      "-\n",
      "Input sentence: but she doesn't want to date.\n",
      "Decoded sentence: he was a long time ago.`\n",
      "-\n",
      "Input sentence: tumescent!\n",
      "Decoded sentence: you know what i mean.`\n",
      "-\n",
      "Input sentence: seems like she could get a date easy enough...\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: that's a shame.\n",
      "Decoded sentence: yes.`\n",
      "-\n",
      "Input sentence: gosh, if only we could find kat a boyfriend...\n",
      "Decoded sentence: really?  i don't know what to say.`\n",
      "-\n",
      "Input sentence: what about him?\n",
      "Decoded sentence: he was a long time ago.`\n",
      "-\n",
      "Input sentence: what makes you think he'll do it?\n",
      "Decoded sentence: he was there to take the same here.`\n",
      "-\n",
      "Input sentence: did she actually say she'd go out with you?\n",
      "Decoded sentence: we don't know.`\n",
      "-\n",
      "Input sentence: hey.\n",
      "Decoded sentence: hey, i guess.`\n",
      "-\n",
      "Input sentence: are you lost?\n",
      "Decoded sentence: no.`\n",
      "-\n",
      "Input sentence: nope - just came by to chat\n",
      "Decoded sentence: the best way to the comminson.`\n",
      "-\n",
      "Input sentence: william would never have gone to a state school.\n",
      "Decoded sentence: i don't want to be a father.`\n",
      "-\n",
      "Input sentence: william didn't even go to high school\n",
      "Decoded sentence: what do you want?`\n",
      "-\n",
      "Input sentence: that's never been proven\n",
      "Decoded sentence: i was all right.`\n",
      "-\n",
      "Input sentence: c'esc ma tete. this is my head\n",
      "Decoded sentence: he's a lot of people at the store -- i want to go to the \n",
      "-\n",
      "Input sentence: that's because it's such a nice one.\n",
      "Decoded sentence: you don't have to be so sure.`\n",
      "-\n",
      "Input sentence: there.\n",
      "Decoded sentence: where's the fucking help?`\n",
      "-\n",
      "Input sentence: yeah\n",
      "Decoded sentence: what do you want?`\n",
      "-\n",
      "Input sentence: what do you think?\n",
      "Decoded sentence: i don't know.`\n",
      "-\n",
      "Input sentence: two legs, nice rack...\n",
      "Decoded sentence: what do you want me to do?`\n",
      "-\n",
      "Input sentence: yeah, whatever.  i want you to go out with her.\n",
      "Decoded sentence: that's right.`\n",
      "-\n",
      "Input sentence: sure, sparky.  i'll get right on it.\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: you just said\n",
      "Decoded sentence: i don't know what to say.`\n",
      "-\n",
      "Input sentence: you need money to take a girl out\n",
      "Decoded sentence: i know.`\n",
      "-\n",
      "Input sentence: how much?\n",
      "Decoded sentence: the car what happened to you?`\n",
      "-\n",
      "Input sentence: i can't take a girl like that out on twenty bucks.\n",
      "Decoded sentence: you want to go to the house?`\n",
      "-\n",
      "Input sentence: fine, thirty.\n",
      "Decoded sentence: good evening, mr. deptur.`\n",
      "-\n",
      "Input sentence: take it or leave it.  this isn't a negotiation.\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: i mean wo-man.  how ya doin'?\n",
      "Decoded sentence: i don't know.  i don't know.`\n",
      "-\n",
      "Input sentence: sweating like a pig, actually.  and yourself?\n",
      "Decoded sentence: no.`\n",
      "-\n",
      "Input sentence: there's a way to get a guy's attention.\n",
      "Decoded sentence: yes.`\n",
      "-\n",
      "Input sentence: pick you up friday, then\n",
      "Decoded sentence: i don't know what to say.`\n",
      "-\n",
      "Input sentence: you -- covered in my vomit.\n",
      "Decoded sentence: no, i don't.`\n",
      "-\n",
      "Input sentence: hi\n",
      "Decoded sentence: hi.`\n",
      "-\n",
      "Input sentence: hey -- do you mind?\n",
      "Decoded sentence: nothing.  i don't know.`\n",
      "-\n",
      "Input sentence: my insurance does not cover pms\n",
      "Decoded sentence: the car are surprised they don't want to be here.`\n",
      "-\n",
      "Input sentence: then tell them i had a seizure.\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: is this about sarah lawrence? you punishing me?\n",
      "Decoded sentence: she didn't say that.`\n",
      "-\n",
      "Input sentence: i thought you were punishing me.\n",
      "Decoded sentence: why not?`\n",
      "-\n",
      "Input sentence: why can't we agree on this?\n",
      "Decoded sentence: we have to go with you.`\n",
      "-\n",
      "Input sentence: because you're making decisions for me.\n",
      "Decoded sentence: thanks.`\n",
      "-\n",
      "Input sentence: as a parent, that's my right\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: when i shell out fifty, i expect results.\n",
      "Decoded sentence: i don't want to go to the car.`\n",
      "-\n",
      "Input sentence: i just upped my price\n",
      "Decoded sentence: what are you doing?`\n",
      "-\n",
      "Input sentence: what?\n",
      "Decoded sentence: the commissioner is a bad thing.`\n",
      "-\n",
      "Input sentence: a hundred bucks a date.\n",
      "Decoded sentence: why don't you go to the back here.`\n",
      "-\n",
      "Input sentence: forget it.\n",
      "Decoded sentence: what do you want?`\n",
      "-\n",
      "Input sentence: you have my word.  as a gentleman\n",
      "Decoded sentence: i don't know what to say.`\n",
      "-\n",
      "Input sentence: you're sweet.\n",
      "Decoded sentence: i don't know what to do.`\n",
      "-\n",
      "Input sentence: say it\n",
      "Decoded sentence: so you have the man who checked up here?`\n",
      "-\n",
      "Input sentence: that's where we can help you.  with kat.\n",
      "Decoded sentence: you said you were a good man.`\n",
      "-\n",
      "Input sentence: you two are gonna help me tame the wild beast?\n",
      "Decoded sentence: sure.  the police was a long time ago.`\n",
      "-\n",
      "Input sentence: it's more\n",
      "Decoded sentence: the best will see him in the morning.`\n",
      "-\n",
      "Input sentence: what?!\n",
      "Decoded sentence: i want to go with you.`\n",
      "-\n",
      "Input sentence: good enough.\n",
      "Decoded sentence: good evening, mr. deprons.`\n",
      "-\n",
      "Input sentence: number one.  she hates smokers\n",
      "Decoded sentence: the best will see him in the morning.`\n",
      "-\n",
      "Input sentence: it's a lung cancer issue\n",
      "Decoded sentence: what do you want?`\n",
      "-\n",
      "Input sentence: her favorite uncle\n",
      "Decoded sentence: what are you doing?`\n",
      "-\n",
      "Input sentence: dead at forty-one.\n",
      "Decoded sentence: do you like it?`\n",
      "-\n",
      "Input sentence: are you telling me i'm a -  \"non-smoker\"?\n",
      "Decoded sentence: what do you mean?`\n",
      "-\n",
      "Input sentence: he's pretty!\n",
      "Decoded sentence: he was a long time ago.  i want to go to the car.`\n",
      "-\n",
      "Input sentence: ever been to club skunk?\n",
      "Decoded sentence: yeah.  i think i should go home.`\n",
      "-\n",
      "Input sentence: yeah.\n",
      "Decoded sentence: what do you want?`\n",
      "-\n",
      "Input sentence: gigglepuss is playing there tomorrow night.\n",
      "Decoded sentence: don't be silly.  i love you.`\n",
      "-\n",
      "Input sentence: don't make me do it, man\n",
      "Decoded sentence: she was a long time ago.`\n",
      "-\n",
      "Input sentence: assail your ears for one night.\n",
      "Decoded sentence: i don't know what to do.`\n",
      "-\n",
      "Input sentence: you think this'll work?\n",
      "Decoded sentence: nothing.  i don't know.`\n",
      "-\n",
      "Input sentence: fan of a fan.  you see a couple of minors come in?\n",
      "Decoded sentence: yes, i do.`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: hey.  great show, huh?\n",
      "Decoded sentence: shhh... you want to talk to him?`\n",
      "-\n",
      "Input sentence: \n",
      "Decoded sentence: `\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checkinig out experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(a.history, open(f'{model_name}_training.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum_input_data = np.zeros(\n",
    "    (1, max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "for t, char in enumerate(\"Says who?\"):\n",
    "        dum_input_data[0, t, input_token_index[char]] = 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
